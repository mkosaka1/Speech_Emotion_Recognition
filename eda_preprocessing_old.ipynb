{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "x, sr = librosa.load('/Users/murielkosaka/Desktop/capstone_project/audio/audio_speech_actors_01-24/Actor_01/03-01-01-01-01-01-01.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "print(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveplot(x, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Audio(data=x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "single_mfcc = librosa.feature.mfcc(y=x, sr=sr, n_mfcc=13)\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(3,1,1)\n",
    "librosa.display.specshow(single_mfcc, x_axis='time')\n",
    "plt.ylabel('MFCC')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole Dataset (1440 files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import pandas as pd\n",
    "import glob \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "import os # interface with underlying OS that python is running on\n",
    "import sys\n",
    "import warnings\n",
    "# ignore warnings \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    "\n",
    "Vocal channel (01 = speech, 02 = song).\n",
    "\n",
    "Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
    "\n",
    "Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
    "\n",
    "Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
    "\n",
    "Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "\n",
    "Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
    "\n",
    "So, here's an example of an audio filename. 02-01-06-01-02-01-12.mp4\n",
    "\n",
    "This means the meta data for the audio file is:\n",
    "\n",
    "Video-only (02)\n",
    "\n",
    "Speech (01)\n",
    "\n",
    "Fearful (06)\n",
    "\n",
    "Normal intensity (01)\n",
    "\n",
    "Statement \"dogs\" (02)\n",
    "\n",
    "1st Repetition (01)\n",
    "\n",
    "12th Actor (12) - Female (as the actor ID number is even)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = \"/content/drive/My Drive/audio/audio_speech_actors_01-24/\"\n",
    "actor_folders = os.listdir(audio) #list files in audio directory\n",
    "actor_folders.sort() \n",
    "actor_folders[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find . -name '.DS_Store' -type f -delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "audio = \"/Users/murielkosaka/Desktop/capstone_project/audio/audio_speech_actors_01-24/\"\n",
    "\n",
    "actor_folders = os.listdir(audio) #list files in audio directory\n",
    "actor_folders.sort() \n",
    "actor_folders[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio/audio/audio_speech_actors_01-24/Actor_14\n",
    "# 03-01-02-01-02-01-14.wav\n",
    "\n",
    "emotion = []\n",
    "gender = []\n",
    "file_path = []\n",
    "for i in actor_folders:\n",
    "    filename = os.listdir(audio + i) #iterate over Actor folders\n",
    "    for f in filename: # go through files in Actor folder\n",
    "        part = f.split('.')[0].split('-')\n",
    "        emotion.append(int(part[2]))\n",
    "        bg = int(part[6])\n",
    "        if bg%2 == 0:\n",
    "            bg = \"female\"\n",
    "        else:\n",
    "            bg = \"male\"\n",
    "        gender.append(bg)\n",
    "        file_path.append(audio + i + '/' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(audio + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "audio_df = pd.DataFrame(emotion)\n",
    "audio_df = audio_df.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'})\n",
    "audio_df\n",
    "audio_df = pd.concat([pd.DataFrame(gender),audio_df],axis=1)\n",
    "audio_df.columns = ['gender','emotion']\n",
    "# audio_df['labels'] =audio_df.gender + '_' + audio_df.emotion\n",
    "audio_df = pd.concat([audio_df,pd.DataFrame(file_path, columns = ['path'])],axis=1)\n",
    "# audio_df = audio_df.drop(['gender', 'emotion'], axis=1)\n",
    "# audio_df.labels.value_counts()\n",
    "audio_df\n",
    "\n",
    "# audio_df = pd.DataFrame(emotion)\n",
    "# audio_df = audio_df.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'})\n",
    "# audio_df = pd.concat([pd.DataFrame(gender),audio_df],axis=1)\n",
    "# audio_df.columns = ['gender','emotion']\n",
    "# audio_df['labels'] =audio_df.gender + '_' + audio_df.emotion\n",
    "# audio_df = pd.concat([audio_df,pd.DataFrame(file_path, columns = ['path'])],axis=1)\n",
    "# audio_df = audio_df.drop(['gender', 'emotion'], axis=1)\n",
    "# audio_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df.to_csv('audio.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.listdir(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fname = audio + 'Actor_02/03-01-01-01-01-01-02.wav'  #female neutral\n",
    "data_neutral, sr_neutral = librosa.load(fname)\n",
    "plt.figure(figsize=(10, 5))\n",
    "librosa.display.waveplot(data_neutral, sr=sr_neutral)\n",
    "ipd.Audio(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fname = audio + 'Actor_02/03-01-02-01-01-01-02.wav'  #female calm\n",
    "data, sampling_rate = librosa.load(fname)\n",
    "plt.figure(figsize=(10, 5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)\n",
    "ipd.Audio(fname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC\n",
    "### The mel frequency cepstral coefficients (MFCCs) of a signal are a small set of features (usually about 10–20) which concisely describe the overall shape of a spectral envelope. MFCC is a good \"representation\" of the vocal tract that produces the sound. Think of it like an x-ray of your mouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_mfcc = librosa.feature.mfcc(y=data_neutral, sr=sr_neutral, n_mfcc=13)\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(3,1,1)\n",
    "librosa.display.specshow(fa_mfcc, x_axis='time')\n",
    "plt.ylabel('MFCC')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFCC\n",
    "#The mel frequency cepstral coefficients (MFCCs) of a signal are a small set of features \n",
    "#(usually about 10–20) which concisely describe the overall shape of a spectral envelope.\n",
    "# good \"representation\" of the vocal tract that produces the sound. Think of it like an \n",
    "# x-ray of your mouth\n",
    "mfcc = librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=13)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(3,1,1)\n",
    "librosa.display.specshow(mfcc, x_axis='time')\n",
    "plt.ylabel('MFCC')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Male surprised\n",
    "pathh = audio + 'Actor_09/03-01-08-02-02-02-09.wav'\n",
    "X, sample_rate = librosa.load(pathh, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "male = librosa.feature.spectral_centroid(y=X, sr=sample_rate)\n",
    "male = np.mean(librosa.feature.spectral_centroid(y=X, sr=sample_rate), axis=0)\n",
    "print(len(male))\n",
    "\n",
    "# Female surprised\n",
    "path= audio + 'Actor_08/03-01-08-02-02-02-08.wav'\n",
    "X, sample_rate = librosa.load(path,duration=2.5,sr=22050*2,offset=0.5)\n",
    "female = librosa.feature.spectral_centroid(y=X, sr=sample_rate)\n",
    "female = np.mean(librosa.feature.spectral_centroid(y=X, sr=sample_rate), axis=0)\n",
    "print(len(female))\n",
    "\n",
    "# Male happy\n",
    "pathh = audio + 'Actor_09/03-01-03-02-02-02-09.wav'\n",
    "X, sample_rate = librosa.load(pathh, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "male1 = librosa.feature.spectral_centroid(y=X, sr=sample_rate)\n",
    "male1 = np.mean(librosa.feature.spectral_centroid(y=X, sr=sample_rate), axis=0)\n",
    "print(len(male1))\n",
    "\n",
    "# Female happy\n",
    "path= audio + 'Actor_08/03-01-03-02-02-02-08.wav'\n",
    "X, sample_rate = librosa.load(path,duration=2.5,sr=22050*2,offset=0.5)\n",
    "female1 = librosa.feature.spectral_centroid(y=X, sr=sample_rate)\n",
    "female1 = np.mean(librosa.feature.spectral_centroid(y=X, sr=sample_rate), axis=0)\n",
    "print(len(female1))\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(female, label='Female Surprised')\n",
    "plt.plot(male, label='Male Surprised')\n",
    "plt.plot(female1, label='Female happy')\n",
    "plt.plot(male1, label='Male happy')\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Male surprised\n",
    "pathh = audio + 'Actor_09/03-01-08-02-02-02-09.wav'\n",
    "X, sample_rate = librosa.load(pathh, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "male = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)\n",
    "male = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13), axis=0)\n",
    "print(len(male))\n",
    "\n",
    "# Female surprised\n",
    "path= audio + 'Actor_08/03-01-08-02-02-02-08.wav'\n",
    "X, sample_rate = librosa.load(path,duration=2.5,sr=22050*2,offset=0.5)\n",
    "female = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)\n",
    "female = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13), axis=0)\n",
    "print(len(female))\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(female, label='Female Surprised')\n",
    "plt.plot(male, label='Male Surprised')\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrogram - how the audio spectrum varies as a function of time\n",
    "spectrogram = librosa.feature.melspectrogram(y=X, sr=sampling_rate)\n",
    "db_spec = librosa.power_to_db(spectrogram, ref=np.max,)\n",
    "librosa.display.specshow(db_spec,y_axis='mel', x_axis='time', sr=sampling_rate)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['log_spec'])\n",
    "\n",
    "counter=0\n",
    "\n",
    "for index,path in enumerate(audio_df.path):\n",
    "    #get wave representation\n",
    "    X, sample_rate = librosa.load(path, res_type='kaiser_fast',duration=3,sr=44100,offset=0.5)\n",
    "        \n",
    "#     #Mel-frequency cepstral coefficients (MFCCs)\n",
    "#     mfcc = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)\n",
    "#     #temporal averaging\n",
    "#     mfcc=np.mean(mfcc,axis=0)\n",
    "    \n",
    "    #get the mel-scaled spectrogram (ransform both the y-axis (frequency) to log scale, and the “color” axis (amplitude) to Decibels, which is kinda the log scale of amplitudes.)\n",
    "    spectrogram = librosa.feature.melspectrogram(y=X, sr=sample_rate, n_mels=128,fmax=8000) \n",
    "    db_spec = librosa.power_to_db(spectrogram)\n",
    "    #temporally average spectrogram\n",
    "    log_spectrogram = np.mean(db_spec, axis = 0)\n",
    "    \n",
    "#     #compute chroma energy (pertains to 12 different pitch classes)\n",
    "#     chroma = librosa.feature.chroma_stft(y=X, sr=sample_rate)\n",
    "#     #temporally average chroma\n",
    "#     chroma = np.mean(chroma, axis = 0)\n",
    "    \n",
    "    # #compute spectral contrast\n",
    "    # contrast = librosa.feature.spectral_contrast(y=X, sr=sample_rate)\n",
    "    # contrast = np.mean(contrast, axis= 0)\n",
    "\n",
    "    # compute zero-crossing-rate (zcr:the zcr is the rate of sign changes along a signal i.e.m the rate at \n",
    "    # which the signal changes from positive to negative or back - separation of voiced andunvoiced speech.)\n",
    "    # zcr = librosa.feature.zero_crossing_rate(y=X)\n",
    "    # zcr = np.mean(zcr, axis= 0)\n",
    "    \n",
    "    df.loc[counter] = [log_spectrogram]\n",
    "    counter=counter+1   \n",
    "\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_feature(file_name, mfcc, chroma, mel):\n",
    "#     with soundfile.SoundFile(file_name) as sound_file:\n",
    "#         X = sound_file.read(dtype=\"float32\")\n",
    "#         sample_rate=sound_file.samplerate\n",
    "#         if chroma:\n",
    "#             stft=np.abs(librosa.stft(X))\n",
    "#         result=np.array([])\n",
    "#         if mfcc:\n",
    "#             mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "#             result=np.hstack((result, mfccs))\n",
    "#         if chroma:\n",
    "#             chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "#             result=np.hstack((result, chroma))\n",
    "#         if mel:\n",
    "#             mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "#             result=np.hstack((result, mel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Dense, Embedding, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET MEANS TO THEIR OWN COLUMNS\n",
    "df_combined = pd.concat([audio_df,pd.DataFrame(df['log_spec'].values.tolist()),\n",
    "#                          pd.DataFrame(df['chroma_feat'].values.tolist()),\n",
    "#                          pd.DataFrame(df['spec_feat'].values.tolist())\n",
    "                         ],axis=1)\n",
    "df_combined = df_combined.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.drop(columns='gender',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions=df_combined.emotion\n",
    "emotions.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SET MEANS TO THEIR OWN COLUMNS\n",
    "\n",
    "df_combined = pd.concat([audio_df,pd.DataFrame(df['mfcc_feature'].values.tolist()),pd.DataFrame(df_chroma['chroma_feat'].values.tolist())],axis=1)\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SET MEANS TO THEIR OWN COLUMNS\n",
    "df = pd.concat([audio_df,pd.DataFrame(df['mfcc_feature'].values.tolist())],axis=1)\n",
    "df=df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TRAIN TEST SPLIT\n",
    "X_model, X_test, y_model, y_test = train_test_split(df_combined.drop(['path','emotion'],axis=1)\n",
    "                                                    , df_combined.emotion\n",
    "                                                    , test_size=0.25\n",
    "                                                    , shuffle=True\n",
    "                                                    , random_state=42\n",
    "                                                   )\n",
    "# TRAIN TEST SPLIT\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_model\n",
    "                                                    , y_model\n",
    "                                                    , test_size=0.25\n",
    "                                                    , shuffle=True\n",
    "                                                    , random_state=42\n",
    "                                                   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE DATA\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "\n",
    "X_train = (X_train - mean)/std\n",
    "X_test = (X_test - mean)/std\n",
    "X_validation = (X_validation - mean) / std\n",
    "\n",
    "\n",
    "# Check the dataset now \n",
    "# X_train[150:160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TURN DATA INTO ARRAYS FOR KERAS\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "X_validation=np.array(X_validation)\n",
    "y_validation=np.array(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE HOT ENCODE THE TARGET\n",
    "# CNN REQUIRES INPUT AND OUTPUT ARE NUMBERS\n",
    "lb = LabelEncoder()\n",
    "y_train = to_categorical(lb.fit_transform(y_train))\n",
    "y_test = to_categorical(lb.fit_transform(y_test))\n",
    "y_validation = to_categorical(lb.fit_transform(y_validation))\n",
    "\n",
    "\n",
    "print(y_validation[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time series data requires kernel sliding in only one dimension and have spatial properties: 1d CNN\n",
    "# reshape data to 3d tensor\n",
    "X_train = X_train[:,:,np.newaxis]\n",
    "X_test = X_test[:,:,np.newaxis]\n",
    "X_validation = X_validation[:,:,np.newaxis]\n",
    "\n",
    "X_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.optimizers import SGD\n",
    "from keras.constraints import max_norm\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "# acc-51,test acc-48\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, kernel_size=(10), activation='relu', input_shape=(X_train.shape[1],1)))\n",
    "model.add(Conv1D(128, kernel_size=(10),activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(128, kernel_size=(10),activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(Conv1D(256, kernel_size=(4), activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "model.summary()\n",
    "opt = keras.optimizers.Adam(lr=0.0001)\n",
    "\n",
    "# #acc-61,test acc-54\n",
    "# model = Sequential()\n",
    "# model.add(Conv1D(64, kernel_size=(8), activation='relu', input_shape=(X_train.shape[1],1)))\n",
    "# model.add(Conv1D(128, kernel_size=(8),activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=(8)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Conv1D(128, kernel_size=(8),activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling1D(pool_size=(8)))\n",
    "# model.add(Dropout(0.2))\n",
    "# # model.add(Conv1D(256, kernel_size=(4), activation='relu'))\n",
    "# # model.add(MaxPooling1D(pool_size=(2)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(8, activation='softmax'))\n",
    "# model.summary()\n",
    "# opt = keras.optimizers.Adam(lr=0.0001)\n",
    "\n",
    "# acc-82, test acc-49\n",
    "# model = Sequential()\n",
    "# model.add(Conv1D(64, kernel_size=(8), activation='relu', input_shape=(X_train.shape[1],1)))\n",
    "# model.add(Conv1D(64, kernel_size=(8),activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=(4)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Conv1D(128, kernel_size=(8),activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling1D(pool_size=(4)))\n",
    "# model.add(Dropout(0.2))\n",
    "# # model.add(Conv1D(256, kernel_size=(4), activation='relu'))\n",
    "# # model.add(MaxPooling1D(pool_size=(2)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(8, activation='softmax'))\n",
    "# model.summary()\n",
    "# opt = keras.optimizers.Adam(lr=0.0001)\n",
    "\n",
    "\n",
    "#BUILD CNN MODEL (even accuracy scores)\n",
    "# model = Sequential()\n",
    "# model.add(Conv1D(32, kernel_size=(8), activation='relu', input_shape=(X_train.shape[1],1)))\n",
    "# model.add(Conv1D(64, kernel_size=(8),activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=(4)))\n",
    "# model.add(Dropout(0.4))\n",
    "# model.add(Conv1D(128, kernel_size=(8),activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling1D(pool_size=(4)))\n",
    "# model.add(Dropout(0.4))\n",
    "# # model.add(Conv1D(256, kernel_size=(4), activation='relu'))\n",
    "# # model.add(MaxPooling1D(pool_size=(2)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(8, activation='softmax'))\n",
    "# model.summary()\n",
    "# opt = keras.optimizers.Adam(lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "cb = ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True)\n",
    "# FIT MODEL\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "model_history=model.fit(X_train, y_train,batch_size=32, epochs=50, validation_data=(X_validation, y_validation),callbacks=[cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Loss of the model is - \" , model.evaluate(X_test,y_test)[0])\n",
    "print(\"Accuracy of the model is - \" , model.evaluate(X_test,y_test)[1]*100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model_history.history['acc'])\n",
    "plt.plot(model_history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test, batch_size=32)\n",
    "predictions=predictions.argmax(axis=1)\n",
    "actual=y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(actual, predictions)\n",
    "plt.figure(figsize = (12, 10))\n",
    "cm = pd.DataFrame(cm , index = [i for i in lb.classes_] , columns = [i for i in lb.classes_])\n",
    "ax = sns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='')\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.title('Confusion Matrix', size=20)\n",
    "plt.xlabel('Predicted Labels', size=14)\n",
    "plt.ylabel('Actual Labels', size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# predictions \n",
    "predictions = model.predict(X_test, batch_size=32)\n",
    "predictions=predictions.argmax(axis=1)\n",
    "predictions\n",
    "predictions = predictions.astype(int).flatten()\n",
    "predictions = (lb.inverse_transform((predictions)))\n",
    "predictions = pd.DataFrame({'Predicted Values': predictions})\n",
    "\n",
    "# Actual labels\n",
    "actual=y_test.argmax(axis=1)\n",
    "actual = actual.astype(int).flatten()\n",
    "actual = (lb.inverse_transform((actual)))\n",
    "actual = pd.DataFrame({'Actual Values': actual})\n",
    "\n",
    "# Lets combined both of them into a single dataframe\n",
    "finaldf = actual.join(predictions)\n",
    "finaldf[140:150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = audio + 'Actor_09/03-01-04-02-02-02-09.wav'  \n",
    "x, sr = librosa.load(fname)\n",
    "plt.figure(figsize=(10, 5))\n",
    "librosa.display.waveplot(x, sr=sr)\n",
    "\n",
    "# Paly it again to refresh our memory\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(data):\n",
    "    \"\"\"\n",
    "    Adding White Noise.\n",
    "    \"\"\"\n",
    "    # you can take any distribution from https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.random.html\n",
    "    noise_amp = 0.05*np.random.uniform()*np.amax(data)   # more noise reduce the value to 0.5\n",
    "    data = data.astype('float64') + noise_amp * np.random.normal(size=data.shape[0])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = noise(data)\n",
    "plt.figure(figsize=(10, 5))\n",
    "librosa.display.waveplot(data, sr=sr)\n",
    "\n",
    "# Paly it again to refresh our memory\n",
    "ipd.Audio(data, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stretch(data, rate=0.8):\n",
    "    \"\"\"\n",
    "    Streching the Sound. Note that this expands the dataset slightly\n",
    "    \"\"\"\n",
    "    data = librosa.effects.time_stretch(data, rate)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = stretch(data)\n",
    "plt.figure(figsize=(10, 5))\n",
    "librosa.display.waveplot(x, sr=sampling_rate)\n",
    "ipd.Audio(x, rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch(data, sample_rate):\n",
    "    \"\"\"\n",
    "    Pitch Tuning.\n",
    "    \"\"\"\n",
    "    bins_per_octave = 12\n",
    "    pitch_pm = 2\n",
    "    pitch_change =  pitch_pm * 2*(np.random.uniform())   \n",
    "    data = librosa.effects.pitch_shift(data.astype('float64'), \n",
    "                                      sample_rate, n_steps=pitch_change, \n",
    "                                      bins_per_octave=bins_per_octave)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = pitch(data, sr)\n",
    "plt.figure(figsize=(10, 5))\n",
    "librosa.display.waveplot(x, sr=sr)\n",
    "ipd.Audio(x, rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speedNpitch(data):\n",
    "    \"\"\"\n",
    "    peed and Pitch Tuning.\n",
    "    \"\"\"\n",
    "    # you can change low and high here\n",
    "    length_change = np.random.uniform(low=0.8, high = 1)\n",
    "    speed_fac = 1.4  / length_change # try changing 1.0 to 2.0 ... =D\n",
    "    tmp = np.interp(np.arange(0,len(data),speed_fac),np.arange(0,len(data)),data)\n",
    "    minlen = min(data.shape[0], tmp.shape[0])\n",
    "    data *= 0\n",
    "    data[0:minlen] = tmp[0:minlen]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = speedNpitch(data)\n",
    "plt.figure(figsize=(10, 5))\n",
    "librosa.display.waveplot(x, sr=sampling_rate)\n",
    "ipd.Audio(x, rate=sampling_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "hf = h5py.File('best_model.h5', 'r')\n",
    "hf.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TEST SPLIT\n",
    "X_model, X_test, y_model, y_test = train_test_split(df_combined.drop(['path','emotion'],axis=1)\n",
    "                                                    , df_combined.emotion\n",
    "                                                    , test_size=0.25\n",
    "                                                    , shuffle=False\n",
    "                                                    , random_state=42\n",
    "                                                   )\n",
    "# TRAIN TEST SPLIT\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_model\n",
    "                                                    , y_model\n",
    "                                                    , test_size=0.25\n",
    "                                                    , shuffle=False\n",
    "                                                    , random_state=42\n",
    "                                                   )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE DATA\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "\n",
    "X_train = (X_train - mean)/std\n",
    "X_test = (X_test - mean)/std\n",
    "X_validation = (X_validation - mean) / std\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TURN DATA INTO ARRAYS FOR KERAS\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "X_validation=np.array(X_validation)\n",
    "y_validation=np.array(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time series data requires kernel sliding in only one dimension and have spatial properties: 1d CNN\n",
    "# reshape data to 3d tensor\n",
    "X_train = X_train[:,:,np.newaxis]\n",
    "X_test = X_test[:,:,np.newaxis]\n",
    "X_validation = X_validation[:,:,np.newaxis]\n",
    "\n",
    "X_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def make_classifier(optimizer='adam'):\n",
    "    #BUILD CNN MODEL\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, kernel_size=(4), activation='relu', input_shape=(X_train.shape[1],1)))\n",
    "    model.add(Conv1D(64, kernel_size=(4), activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=(2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv1D(64, kernel_size=(4), activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=(2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv1D(128, kernel_size=(4), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=(2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv1D(256, kernel_size=(4), activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=(2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer= 'adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn = make_classifier)\n",
    "params = {\n",
    "    'batch_size':[20,40],\n",
    "    'nb_epoch':[10,15],\n",
    "    'optimizer':['adam','rmsprop']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=classifier,\n",
    "                           param_grid=params,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5)\n",
    "grid_search = grid_search.fit(X_train,y_train)\n",
    "best_param = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (best_param)\n",
    "print (best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
